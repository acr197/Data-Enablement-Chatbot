..	Oatorama - let's Navigate (PT 1)-20250508_11... tf- v	fJ Search	?
Qi	6'IJ Record v  f Upload * Favorite + Playlist	,fj Team, v




CJ

I::::












Datorama - Let's Navigate (PT 1)
MayS,2025  b:p1resin120days  • Oviews • SharePointApp • HO·	> Documents > Recordings



Keep the the dataramas in separate browsers Just so I can distinguish what is what. If I'm moving fast.
So with this one we do not set up.
The actual dashboards in here we don't do anything in the visualize tab.
So hke all of these things that you see on the side here outside of like N2. QA is like set up by the Novartis analyst that they've hired to to set ii up.
So they handle all this. I I to be honest with you, I'd never look at anything in this tab. So typically for this data Rama, I'm gonna analyze and act and connecting connect index.
So once you get your 521 access like your e-mail. Your access to.
This your access to this dataama will happen and
then you'll use your like your your Novartis e-mail to log into it. When you do get the access. Let me know because you should.
••••. They're gonna tellyou that you have to access this through.
Through the C1tr1x Portal. which you don't have to do, you could Just kind of reset your password and then you'll be able to use it on your own computer.
So like when you get the ac s.we can talk more aboutitifit'slike.
lfit comes through like weird.
let's let's talk about connected next
So connected mLX 1s basically hl:e what I consider the back end of datarama.
So this is where all of like the engineering and all of the data enablement stuff happens. So.
We use a few different things m this.
In this menu we use data streams. We use dimensions and we use measurements.
So it's not about the the data streams first.
So this is 1f you go to datastream list this is gomg to house all of the data streams that we have set up that are that have that are coming into.
Data Rama is everythmg coming in as you can see there is a lot in here and not all of it is ours.
So that 1s like important to note is that like some ofthesearetikeconsultantagencies.
They hired some of them are their offshore teams. So we came in and then ! love doing stuff because then they end up copying us. But we labeled all of
our data streams that we have set up with N2, so
we can actually tell which ones are ours.
So this kind of looks very similar to like what we were talking about like the other day.
So hl:ewe have like. The like.
The the PCM snowflake table.
Get ingested into this data stream and delivers data that way.
We have the same thing for like SA 360.
We have stuff for Snapchat and you'll see that there's a few different kinds of like there's a few differenttableswithsimilarnames.
I don't want to talk about Prisma.
So like we have two for 8 of it. One is the actual delivery table and one is a classification table.
So this is like our. Tableinwh1ehl1ke.
We're1r,gestingtheclass1ficationsthatwe've.
That we've set up where we're hke kinda union and joining everything.
To be honest, I don't check the classification tables that often.
I am typically 1f there is an issue. I'm typically looking in the.
Delrverytables.
Umm.
The reason for that is because we do dass1ficat1ons mhere.
So this is kind of just ackling addrtional layers of that classification.
And then there's other ways to check. like if there's classification errors which won't go over well. go

But what 1'11 typically do like if you come into if you click on the data stream, you'!! see a bunch of options at the top.


Edit isJust gonna show you.
Exactly where. where the data'scoming from? SoiflScrolldown.
You'll see the query that's running from Snowflake
to pull in data so you can see that this one is pulling data from another delivery where the date is greater than 2022.
And then the date is.
Greater than equal to the current date, -90 oh. Wait this isexed out? That was out.
So sorry this one the 20221 is no longer valid, so it's actually just pulling current date minus.
90days.
So this isimportant because if we have an innovid like say we have an innovid delivery issue.
For December.
And December 2024 and we fix it with lil:::e whether we had to do a backfill with lil:::e redshift or there was just lik.e a connectivity issue or there was just lik.e some sort of issue with the data in stowilake we will have to talk with engine.
ltypica11y.
You probably saw me the other the other day. Asked about Reddit.
We Just have to have and I typically don't do this
because I'm just worried about .. .,..,., up the data stream so bad. to be frank..
So I typically would Just be like can we run do a one time run of this?
Longer than 90 day:; to get an issue resolved.
That happened in December because right now it's only p,..111ing data from Snowflake back 90 days.
So in order to get the December data, they'll do a one time extension to get data for that Decemb€r time frame and then they'll fix it and I'll bring it backtothe90 days.
And that's the reason why we have this set up is Just 'cause. There's so much data
And there's so much.
There's so many datas, there's so many data streams that MCM Cl is not scalable.
So you can't make it faster, which sucks
Like unlike how we have the different warehouse runs in Snowflake and we can be like, oh. this is going to take 15 minutes, let's do an extra large warehouse run so that it only takes a few seconds.
Like we Lln't do that in in data Rama.
So in order to keep things as speedy as possible, we ti)' to sometimes limit date the date ranges on larger datasets, if that makes sense.
So yeah.so this is.
I'll typically lool::: in here to see like where where if I'm like OK. looking at a data stream issue. I'll typically see like look at where we're pulling from for Snowflake, I'll see. Like what?
Thedaterangeisforit.
We're pulling in that is active flag, so making sure it's only the valid active data datasets to avoid duplication and then.
It's all I typically loo for there and then if you


Like.
A couple other things. Like you know. you can see this is a successful. The last time I ran it it's been successful. lt'senabJed.
So that means it's running like it's running like almostallthetime.lthinkit'sactuallyrunninglike   every two hours from Snowflake.
And then if you come to e.xecution hi5tory, you'll JUstseeallthesuccessful runs.
So you can.
It doesn't always sort.
It kind of sort weird sometimes and it I hate that it does this because if some stuff failed in the past.
It'll show first 'cause there's a new start date, but if you just come down you'll see like OK.
ThisranonMay8th. You could do,
Oh yeah, you could do start execution date. There we go.
But yeah, you can see that the last time 1t ran this file ran. it was successful
So everything came through as as planned. If it's not successful.
So sometimes you'll see that the run status might
show as successful. Sometimes it'll show as invalid. lfit'sinvalid,there'saproblem.
Sometimes this will show a successful and some stuff failed
So I will again to mak.e sure the wrong status within ttie individual file and start execution time was succe55ful. lf we're seeing issues.
And then lastly, like you could or the last two things that we really look at here are mapping and pivot table.
Let me go to the pivot table first
So pivot table will just quickly pivot out the dat,1 that you could find in the data stream.
So this is that data stream.
That I'm looking at. That's lil:::e filtered here and then it brings in a few rows. but then you could bring in like other stutf like campaign ID's, advertiser ID's. The only thing you're not gonna be able to bring in if you're just looking at the that
Singular data stream is our classification, so if you're looking for something that says like, this is kisqali MBC OTC.
That field is not going to populate like our our brand report name
Games and stuff will not populate if you're just looking at thisdata stream, bec.ause that's not located in the data stream that's located in the classification streams.
So you won't see that if you're Just looking here.


And yeah, if you rouldjust we'll go over the pivots and analyze an act. but very, very simple.
The only thing that's a little difficult is just getting the hang of what we name stuff that took me a long time, because I refer to something. If I if I'm looking for something.
I'm typically like going to look like from deep, like from just being on media tech.
I'm going to be like, oh, I need to find a campaign name and not ell'erything is named campaign name. Sometimes, like, you have to look at an adll'ertiserlevel.
So sometimes it's like campaign advertiser. We don't call thingscampaign names or place. We don't things placement names in here.
They'recalledmediabyname.
The media by key is the like Prisma ID that used to
be.
Included all the placements so it Just takes a little bit of use to get like familiar and comfortable with like.
These like l::i11d of catch all names that we use for all ,:;hannels versus just thi11king of like what we've been seeing from like adcm perspective.
So let me go back.
A11d then the last thing on the stream is the mapping.
So when we get the data from Snowflake. it's just all those singular columns. right?
Like we run if you do the select from, you'll see all the columns that are in that in that table.
So ifyou do mapping, you're gonna see.
What we mapped from the from the delivery from Snowflake, so those columns from Snowflake what we mapped to in and into datarama and what the name is for those columns.
So we don't use the exact exact name from Snowtlakecolumns.
We aggregated to other names.
So as you can see like I was saying placement ID, we don't call it a placement ID. In MCI we call it a media buy source tag.
A video name is In.
It's stowflake is a creative name in MCI, so if you're ever just like I have no ideawhattocallthiscertain dimension. you can always come to the mapping and see exactly what you have to have to look for.
You can see at the top we have a bunch of stuff that's unmapped from Snowflake, and that's just because like we don't need it for. It's kind of just like we don't need it right now for innovid like.
lnnovid.
On Novartis, we've used three ad servers we've used DCM. We've used innovid and we've LJsed flash talking whi we use innovative flash talking Just like anything else we do at PHM. DCM is the source of truth.
So like we try to tie everything back using only a few different fields, becaLJse honestly, we're not really concerned about the intimate impressions.
Likewe,yes,wewanttosee. End of impre:s.sions.
We want to make sure that like those teams should be making sure that innovid impressions look very similar to DCM impressions. To make sure there's no tagging issues, but from like an overall metrk:.
Scenario the only thing
That we care about from from lnnovid is video completion rates.
Because everythi11g else should be DCM like, we should just be looking at DCM for the source of truth.
But becaLJse we're not running the video in DCM,
we don't hall'e those video completion metrics.
So yeah. So like you'll see at the top. all the things that we haven't mapped that might be in the columns of snowflake.
And then you'll see all the unwrapped data fields from MCI that like you could map them to if you wanted to.
So if for some reason we decided tomorrow that, hey, we actually have to bring in the campaign ID for innovid, we could take this and map it to say like campaign ID.
Oo.
Or like campaign key on this side on this side and we would we would clearly tall:: about that and determine what is the best data model field set up in order to handle this unmapped ca:s.e.
To be honest with you, I haven't had to map anything since starting, but it's something that we'll probably have to do a little bit more often if we get like new data streams and whatnot.
So like. I feel like Kyle and I have been getting kind of used to this recently, but.
We haven't had to like, really do anything to date. ICyle is working on a project for GSICto get like Dalarama set up. So he's getting a little bit more intothe-dswiththis.
So we'll kind of lean on him to maybe make some like best practice documentation so that if we do have to set up something new on Novartis. we have something to go off of
OK.
So just going to discard that.
But yeah, so again, all of our data streamsto, I'm only really using these to see what the, wtiat it's referencing for Snowflake, what what tables we're using for Snowflake. I'm using it to see like if there if we're having data i:s.sues
Does it? Does the? D0€s the data stream have like a certain date range?
Could the certain date range1 Be impacting it.
Did we maybe update tlie table and stuff like recently and then forget to update the the table in th<><lllPnJ hPrP to rpfJpet thP nPWPd t:.hlP?


And then JU5t looking to see like if the data streams have have failed.
And then che.::k in to ;ee what it's made to. lt"sbasicallyallweuseitfor.
Any questions like immediate questions about about this?

•• Andrew Ryan 16:35
Not really. No, not yet

R.ichelPiot 16:36
OK
OK. it does it.
Doe:1-itmakesensethough?
Like kind of like how we're just kind of feeding
We're basically;ust feeding those different views andsrmvvflakeintoMCI.

., Andrew Ryan 16:5-0
Yeah, 11 gotta understand where it's coming and I'm keeping the the data flow chart in front of me just to make sure because like
Seeing how this comes so it goes from there.
Snowflake to their data, Rama into ours and then theotherpartisthatlt's really just a emailed report to the other thing
That"s not what we·re looking at here. rightJ OK
gotcha.


Rach l Pio! 17:09
Yeah, No. we're not.
We're gonna. We're gonna have a whole day to talk about the e-mail reports be.::ause that is, like kind of a nightmare.

•• And Ryan 17,16
OK


:_  Rach l Pio! 17:20
That m.-'re hoping the software with like having like trying to use Reverie instead of pub media for certain platforms.
But we'll talk about that another day.
Thi is pretty much valid like

'i And  Ryan 17,31
OK


Rach l Pio! 17:34
For like if we're talking data streams like just here like so this would.
OK, let me let me rephrase th
Even the data streams that are going into our MCI.
Are doing kind of like a big roller coaster loop back into our MCI like as a final view with classification.
S.o even if stuff is taking.
If if things are going the path of redshift. Into snowflake.
Into Novartis
Data Rama into our datarama the emailed reports are kind of doing the same thing, but from the opposite end.
S.o that one is going.


., Andrrw Ryan 18:24
Mm hmm.


R.ichelPiot 18:26
UI to RN 2 MCI.
Two, snowflake Into Novartis MCI.
S.o they're both kind of taking two separate routes and then still landing in the same spot.
The same way.


•• AndrrwRyan 18:41
Mm hmm.



Does that make sense? OK.


•• AndrewRyan 18:48
Actually in thischart



Yeah.


•• MdrrwRyan 18:5-0
It does say that our datarama yous.aid it goes from our datarama to snowflake, b1Jt01Jrs s.ays it goes in the data bricks first and then into Snowflake.



Yeah, Yes, ! always forget about data bars because it's like01Jt of sight out of mind to be•

., Andrew Ryan 19:00 Yes and no.Oh.OK. Gotcha



We involved a lot more with Data Brix moving forward, but right now it'sjust kind of been this like silent operator for me because we don't typically have to check anything in there because we have stuff like if we didn't have snowflake data, bricks would be our snow

And Ryan 19:16
Mm hmm.


<:,ot you. UK.cool.


R.ichelPiot 19-.21
So yeah.cool.
OK
S.o this was pretty much all we do in the data


Another thing that I llke to use a lot is this data mapping visualizer.
S.o sometimes J'm like like I'm looking at something in MCI arid I'm like, I have no idea where this is pulling from.
And I do not want to look through every single data stream lo figure out where this is pulling from, like what is mapped to this
S.o if this loads..this is the one problem about It is that sometimes this takes forever to load, but once it loads.
You can sear(h for an MCI dimension.
Or metrk and it will then show you a visualization mapping to each data stream.
That is, that data is getting pulled from into that metric. I find this extremely helpful because sometimes I'm like I don't remember what this I don"t remember what thi ern:ompasses
I don't remember what where we're getting data for this and then this will just show me real quickly like.
What data streams apply to this metric or this dimension?
I'm gonna let this load in ttie background.
But yeah. I in data streams J'm typically only rigtit now using data streamlist and data mapping visualiLer.
Do I think we use data mapping at all?
It's kind of the 53me thing as the visualiLer. but I find the visualizer
Way more helpful when it loads, and honestly some I didn't think this through, but some streams might be running right now slowing down.
This account it is 82% used. OK
All right. S.O let's talk about dimensions and and


S.o in these lists you'll see like where you can see like a dimension list.
Calculate dimensions and hierarchies are typkally the things that I use the most.
Let's look at the dimension fist.
So this just gives you literally a list of all the dimensions that are that are set up and these dimensions are not.
Like manipulated in any way is what I should say like.
S.oit's like if you search. Oh wait.
Like I'm trying to think of a metrk: that we don"t.
OK.perfe<:L
Solikecampaignadvertiserlikeattheend of the day, the campaign advertiser is the campaign advertiser.
We're not manually manipulating anything to have it determine it's a campaign adveniser
Oh. here we go.
Let's go back to data visualization really quick.
S.o yeah. this is the mapping visualizer to say if I wanted to see like what?
Where are we getting media cost from? Is a big is a big one.
Like this is one I thinl:::I have to look up all the time because like Costco is from different platforms. If you click on this.
And e>Cp<md it.
It'll tell you every single data stream that feeds media cost in the in MCI.
S.o we're getting cost from Google ads YouTube, we're getting like and what what those different? It'll also show you what that iscalled in each different like data stream.
Before you map it to MCI.
Like Meta, rt's pulling from meta It's pulling the spend from meta.
It's pulling the spend column from fiklok. It's pulling spent from Linkedln.
Why do they call i1 spenL That's so weird
It, like you will see lil:::e plan them out.
We're going to plan them out from Prisma, that is lo determine DCM.
We're pulling cost from FA 360. so it'll show. S.how you exactly.
Where tliat is coming from and what data stream. S.o I love this visualizer because like I get confused like especially with like. I'm not reall•y

._ Andrew Ryan 23:33 Very pretty.



Yeah, rm like. rm not familiar with print. Whereisthisrnmingfrom?
S.olikethis is really helpful. And that's all it does.
And like you can just click it and then sometimes I'll highlight stuff or I copy the names and place it in that.
In that pivot table like filter for one of these
Data streams in order to see like an issue. so it doesn't have to look through all the different data streams to find what I'm asking it for.
Cool. So yeah, this is this is really helpful. OK
So yeah this.

I don·t know what happened here.
Yeah. So these are all just the like. these are all like wliat I like to call static like dimensions.
So this is just what like I could pay an adverfaer as a campaign advertiser. This is this like we're not manipulating any.
Thing to into a bucket of sorts. Let's;ust put it that way.
So the campaign name is campaign name Camp;iign start date is campaign start date.
Calculated dimensions is what we work in the most and what I have time set up on the calendar to start talking to you about next week.
Ttiis is kind of like the right now tlie bread and butter of us trying to classify data.
So and this gets like it does get very confusing.
So l'm not going to go through too many things today, but.
Let's lool:::at
01(, brand report name so and we might have to

I'm actually looking at this now and l"m noticing that these other teams are coming in and adding stuff.
I might have to come in here and actually add N 2 before all of ours, because this is gonna get very confusing unless you're familiar with like all of our fields.
So !'II do the same thing that we did for the data streams and the calculated dimensions because some of these, like this ones not not ours, they basicallyJust lil::e =py what we did
To see when ldo.

._ AndrewRyan 25:44
People really underestimate dean names.

R.ichelPiot 25:44
But.
Yeah. Oh. yeah, I know

._ AndrewRyan 25:47
Just I name like ENery file that goes my downloads not every file but like.
Need to make it searctiable.

R.ichelPiot 25:54
I get it.

•• And,--Ry,m 25:54
I need to know what l"m looking for.

Rach l Pio! 25:56
I know I get it I understand.
So yeah. so brand report name. So I think I mentioneditbeforethatwehave.
We have technically.
3 views of like similar to how we have like the in Snowflake, we have like the STG, we have the int and we have the bio
We have similar.
We have a similar setup wrth classifications, so we have and I'm. Sometimes you'll see qai honestly don't know why they did AOA in Dev here.
Historically that does not make any sense to me. But that we use Dev.
We use the regular named one with.
Nothing in front of it.
And then we use RI. So think of it this way.
That is where we work in to test it out and s.ee if it works and 5ee make sure it doesn"t break anyttiing elSE-.
If everytliing looks good and everything looks right we push it to what the?
Just the regular name. This is considered live. Onceit'slive,Novartiscanse..-it
Novartis can see, like allthe updates that we made and then RI is our re-immersion.
And so this is the thing that takes the loop back into Snowflake and it gets readjusted into MCI and allthisisaftatfile
It just helps to speed up usage.
So, like RI is if we're talking with people at Novartis or we're running reports on our end or doing pivots on our end, I try to use the RI because again it's a plat file and it's going to run really fast
Asked.
And that's all. It's basically used for.
So we·re basically operating in Dev RI and then the regular named one.
I'm we·re l"m trying to set up a the rigtit now and this is the thing that I was talking to you about and we·11 kind of get into this a little bit more about like trying to set up AQA and data Brix.
We have a report and I'll show it to you after where we pullthese like we basically pull
Right now we're just pulling in Dev and the regular name, and ifwe mal::ean update in Dev.
We pull a repon that .3 huge report that shows all the death fields and all the regular field and we check to see like if anything that we made in Dev negatively impact anything for any other columns before we push it live.
It's like a way to check that the code that we made here.
Doesn't mess with anything else What we're trying to do is.
There there, there's a better way to QA this like on a daily basis. And we're gonna try to figure out a way to feed the classification. Uke report that we·re doing this information in and tiave it post oh, this this line and Rhode Island have it pull in.
The data bricks and then have data bricks run just a true false on it.

board.
S.o that way we can kind of catch any errors before like we try to do a QA for the week because this takes a lot of time to do.
And Kyle?
Kyle has been patiently doing it, but it's not perfect.
S.o like. I think ifwe can get romething manual or automated going and data bricks, it'll kind of;ust provide us a safety net in case something goes wrong.
But we had something happen recently where like we were queuing dev and this and for some

And people were telling us that the RI was wrong and there was some kind of hiccup in Snowflake side of it readJusting the like Reimmersion field. And we had no idea because we haven't been looking at this
We we're we're only looking at these two.
S.o now we're gonna look at all three.
But let me show you really quick like this is what I was talking about with like the kind of SQL MCI, SQLbased stuff.
And again, we'll go through this more in depth, but like thi i> where we work in this is where we make updates.
And then if the updates look good in here, then I'll have Kyle basically copy. And when I say push it l basically have him copy and paste it into into the regular.
The regular field and then once it does that, that reprocessing and the snowflake the update that we made here will show here.
Doe:1t-hat make sense to some degree?


•• AndnewRyan 30:43
For the most part.


:_  RachelPiot 30:44
OK
Yeati. And we'll, we'll go through clas:1-ifications way more in depth
We're gonna do like 3. Like a base of lil:::e a three parter on it

•• AndnewRyan 30:51
Mm hmm.


:_  RachelPiot 30:52
'Cause, there's just a lot of information here. but we we work again mostly in here in dimensions. If I need to find other dimensions ttiat are in use, I'll sometimes look: here, but for the most part just calculate dimension:s..

••  Andr- Ryan 30:54
Yeah.


R.ichelPiot 31:03
S.ame thing with dimensions.
It's the same exact thing, except it':1-just


S.o you can find like the impression stuff the like conversion, all of that information here revenue.
And then calculate measurements we don't have as many four. There's not as many things that we need to do here.
So ifs mostly where we're operating in, in dimensions, so.
S.o this is pretty much the overview of the connectomex. Again. we're only touching a few fields inhere
Let's go to analyze and act and talk a little bit more about reporting, OK. so.
Basically. Once. OK.
So Ada from Snowflake goes to Novartis data Rama.
We do all of our classifications in data Rama. We like manipulate data, standardize everything.
Those classifications get readjusted into Snowflake aswell
Data comes back in.
Clas.sifred in that re immersion. Process. So now we have.
Let'sthinl,;ofit.
OK, that it's run this full process da:1-sified re immersion data is back in Novartis. MCI.
How do we get that data into back into Novartis at the end 2 MCI.
S.o what we do is
We actually just have. Reporting exports out.
So we·re just basically exporting the the
REIMMERSION data.
From our NBS MCI back into N2, MCI and so when you when we tall:::about N2 MCI tomorrow.
These exports come into N2, MCI as a data stream
S.o N2 data stream is fed by N2 elCports NBS data streams are fed by Snowflake. Umm.
We typically don't update anytliing on exports. Sometimes I'll rerun it if. lil::e we've made an update and we need it back into M2. MCI ASAP. I might just like dick on something I did the other day and rerun it cau:1-e those those.
Data streams in RN2 MCI is Just doing lil:::e a like a replace everyday when we run it.
My one thing that I want to bring up is that. And ll'llreiteratethisto Kyle.
Wtioisawhateverissetuphere? Don't touch anything.


may cause. Jackie won't know either.
Dm1't add or edit anything, especially the time period.
Don't change the time period or anything on this. I learned thi!; the hard way.
Where I updated the time frame thinking it was wrong.
And then I accidentally doubled all the data.
In our MCI for an overlapping month and there was no way to fix it other than me just like changing the dates in the report again to like make sure reports sit and overlap and it took me like 3 eks to figure it out so.
We're short Don't make any updates when the within the exports until you talk to me and then.
You do have to do anything here, just like rerun the report.
Got it.


•• Andr- Ryan 3 :06
Got it. Yes.


RachelPiot 35:07
Cool. Yeah, there"s a headache
I was like, oh. this should be easy to fix. It was not. ltwasnot.
It was like I was like two months in when I did it
t=.
Solwaslikehow? How do!?
How do ( even fix this?
OK.
So that's all that we're doing here
There are a few other reports that we'll get into a little later, but like we do some stuff for iqv not super important right now. but they do not have.
There's some stuff that, like, gets pulled out of here that doesn't get exported into our into datarnma, but we'll talk a little bit more about that later.
And then pivot tables we started talking about
So you can literally, once you have access, you can come in here and create like as many pivot tables like as you need or you want sometimes if I'm looking up similar stuff. I'll just use the same table over and over and over again.
But you could just hit create new.
And then you'll alwaY5 see that the date range is to 2085 or is something in the system that somebody like lypoed the wrong end date. and now you always have to change it back.
To just look up the time frame that you're looking for.and theneverythingelseisverysimple
You just click this to add fields. So ifl need it again
If I'm with replacement name, it'.s not placement
name in here, it's media by name. Look it up, you'll find it.
You can if you need.
A reimmersion field, so like brand report name would be one of them.
You can Just pull in the reimmersion if you want to see if it's the same across all three. You could pull in all three of them and see if it. If it mirrors each other and then you look up those rows and columns in the same area. So.
Like you could do impressions. There are 100.
Like different things so.
Just Scroll down the delivery here and then you can find just impressions is a big one. I pull in all the time clicks
Same thing, Just Scroll down to delivery.
Media cost i5 one that I pull in quite frequently. And.
Plan amount
From Prisma I pull in. I could give you a list too of all the ones that I use the most frequently, but you can pull that all in here and then if you want to add any filters.
So I typically, if I lmow I'm looking for ;ust like a single panel
I will select the buy channel.
And I'll just like put like rnmpaigns social. MCliscasesensitivetoo.
So might have to try a different like, I know for a
fact our buy channels are structured like thi1o, but some of our brand names are like capitalized some of them like aren't.
So unfortunately.just like you might have to search forafewdifferentones.
But I'll typically do a bkhannel filter to narrow stuff down if I want to check all the data streams. If there's one specific data stream I need to look at like for social.
I can literally just come here and type in data


And then let's see if the li t works sometimes. Oh,itisOK.
Sometimes it doesn't load right away. but you could type in sosh and then you can find the delivery table.
And you can add a bunch of them too if you like.
Because again, sometimes l"m looking for stuff and I know it's not all in that om.>table.
So sometimes it's better to just add a channel filter versus like a string filter.
Actually. I'm curious about something That I never tried before.
Sometimes it freezes..That'.sfine. There we go.
Hey, that's cool.
So you can bring the data stream. So I never had

to use that. Oh, tJut am I tmng1ng Just the parent: I'll talk about that another time, but yeah, so.
That's it with the pivots.
It's great too, because once you start pivoting, you can it'll pivot out, but you can do a flat table.
So you can just look al everything sKle by side and then once you have your data in here. So let me go back and show you


I also have this filter just to look for stuff that I created cause again there's like hundreds of people using this.
But yeah, I had to look up.
I waslooking at the Reddit information that I had dropped in the chat the other day, so like I was looking for the time frame where Pop Media was able to backfill for basically with Reddit we were missing spend.
Intermittently, across all oftheir campaigns for like all of 2024 and 202.5, they ended up having an issue with the platform thattheyhadtolikerectify to get it coming through properly.
When they were finally able, I opened this ticket in November, by the way
It'sjust getting fixed.
When I they were finally able to address the issue. they could only backfill for one year to date. so they were only able to get us fixed data from April 9,2024onward.
But what I had been doing is. I've been pulling.
I was pulling the state range
And this happens sometimes too. It times out.
Very fun
I was pulling for this timeframe just to compare what we had originally pulled from the UI to see if it matched and the good news is, is it does now the UI matches for this time frame, but as you can see like now we have OK we have.
Data we have spend data or cost data onboard from April 9th, but we don't have anything for January,February,MarchupuntilAprilBth.So wliat?
Were the engineering helped us fix? Helped us fix.
Tlietables.
And get that data going.
But now we ha11e to have engineering manually backfill January through April 8th data and what tliey do there is like Wf' just all we do is provide tliem UI reports in the format that they need ii and
!lien they go in an,d manually append it to tlie


Table I liave no idea how they do it To me, it's like magic, bu•t

., Alldrew Ryan 41:57 I bet they love that.

Ra-chelPiot 41:58
Yeali. I know exactly.
But they just let me know once it"s appended and then all we do is then go ahead and Qi and make sure that now what we're seeing is Snowflake.
And MCI match the UI for that for that date range. So as you can see, I was looking up like I ended up pulling in partner.
I pulled in our like lpmm brand name and tlien I pulled in the campaign advertiser.
So this is liketheactualadvertiserasit'slistedin the platform
And then what I did is I pulled immediate impression a media cost.
And !lien I just filtered down here by Reddit. And lhenwt,at?
I what I like to do is I use.
I lil::etomakeitaflat table. ltmakesitdeaner.
Tliis is right. The reason why this is like this is I think because we had them update the names at some point so that they were consistent.
So you can.
This is my doing.
I think you'd be happy to see consistency.
This one's not updated because it's an older campaign that is no longer alive, that we no longer have access to

._ AlldrrwRyan 41:05
Beautiful.


Ra-c:helPiot 43:B
S.o I was just lil::ethat'sit.


Tliisalllil::e matches.
Now thisdata matches and then what I what you could do is )"OU can actually just click download it as a flat table or pivot as well
S.o yeah, that's so once you ha11e access to, once you have access to the Novartis MCI, you"tl be able to do this.
And you can like play around.
You can start looking around and and like gathering questions that you might have.
You don't have tlie ability to do this in our N2 right now because we're waiting on more licenses.
Lil::elicenses?
S.o I think in our end to MCI. you can only see visualize right now which is fine.
Once they get the more once they get that figured out then you'll get a licensed account and then you'll be able lo access like all three of these In our own data Rama as well.


Yeah, And thars thal"s pretty much 11. Any questions?

•• Andrrw Ryan 44:24
I don't think I mean everything you're showing me makes sense. How these parts of the platform go. And like I think it comes back to Oil€ of the first things you said is just like once all the dots really connect that's when I feel like I'll have like.

Rach Piol 44:28
Cool. Yeah

7i AndrrwRyan 44:39
A manageable grasp on this everything you're doing is like. oh. I'm like, I could do that.
I could do it
I just don't know when or like you know. I haven't been assigned to test but I appreciate it



Yeah


•• AndrrwRy"n 44:49
It's good to know. It's good to see it.



Cool.


•• Andrrw Ryan 44:51
But yeah, I'm piercing things together a little bit. but think over the next few weeks between you and Kyle
Get there.



Yeah, absolutely.
And again, we"ll, we'll do thisagain tomorrow.
And we'll talk more about we'll just kind I show you the data streams that we're getting from the e)(port here and then we'll talk a little bit more again about the dashboard.
And kind of go through, Like what?
Maybe we can even. I think they started submitting a few tickets, so maybe w,e can even talk about some of the tickets that the that the team has submitted.
Umm,
And then we'll go over Classific.
We'll we'll do classifications nelCI:week and I'll show you like exactly what we've been doing there. like how we've been updating. how we've been QA ING. And then I think that'll become a little bit more clear about. like, you'll see it like the actual updating of the class.
Always looks a little like crazy. but then once you see the report tt,at we're pulling, you're gonna be like.
Oh. this i:s like comparing. It it's almost.
It's like comparing the traffic workbook to like the trafficking and like having to like how we had all those old like true or false is set up like. That's pretty much what we've been doing and we just like wanna try to figure out how to automate that

We don't have to, like, constantly look at it ourselves.
So.
Butyeah.


.._ And,--Ryan 46:22
Gr-=at


RachdPiot 46:21
Cool. All right.
Well, do you have any like one-on-one questions that any other one-on-one questions that you that you had?

@ Ra<:helPiot toppedtran cription
